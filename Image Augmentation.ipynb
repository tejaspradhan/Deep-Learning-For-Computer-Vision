{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"E:\\\\Computer Science\\\\Neural Networks and Deep Learning\\\\Datasets\\\\horse-or-human\\\\train\"\n",
    "test_dir = \"E:\\\\Computer Science\\\\Neural Networks and Deep Learning\\\\Datasets\\\\horse-or-human\\\\validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,       # rotating the image by upto 40 degrees in the augmented data\n",
    "      width_shift_range=0.2,   # increasing and decreasing the width of the image\n",
    "      height_shift_range=0.2,  # increasing and decreasing the height of the image\n",
    "      shear_range=0.2,         # shear transformations\n",
    "      zoom_range=0.2,          # zooming upto 20% of the original \n",
    "      horizontal_flip=True,    # mirror image\n",
    "      fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size =(300,300),class_mode = 'binary',batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = image.ImageDataGenerator(rescale=1./255)\n",
    "test_generator = train_datagen.flow_from_directory(test_dir,target_size =(300,300),class_mode = 'binary',batch_size = 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16,(3,3),activation='relu',input_shape = (300,300,3)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape = (300,300,3)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu',input_shape = (300,300,3)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(lr=0.001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0704 17:46:59.724829  9392 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0704 17:47:00.777776  9392 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 52 steps, validate for 13 steps\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 85s 2s/step - loss: 1.4333 - accuracy: 0.6884 - val_loss: 1.8770 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 78s 1s/step - loss: 0.5338 - accuracy: 0.7546 - val_loss: 1.7626 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 74s 1s/step - loss: 0.4354 - accuracy: 0.8169 - val_loss: 1.7632 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 74s 1s/step - loss: 0.3327 - accuracy: 0.8500 - val_loss: 1.3019 - val_accuracy: 0.6211\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 81s 2s/step - loss: 0.4177 - accuracy: 0.8870 - val_loss: 1.9907 - val_accuracy: 0.5039\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 86s 2s/step - loss: 0.2726 - accuracy: 0.8929 - val_loss: 1.3941 - val_accuracy: 0.6016\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 81s 2s/step - loss: 0.2321 - accuracy: 0.9104 - val_loss: 2.1278 - val_accuracy: 0.5195\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 81s 2s/step - loss: 0.1819 - accuracy: 0.9289 - val_loss: 1.0024 - val_accuracy: 0.6836\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 83s 2s/step - loss: 0.1758 - accuracy: 0.9474 - val_loss: 3.0467 - val_accuracy: 0.5430\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 79s 2s/step - loss: 0.3578 - accuracy: 0.9367 - val_loss: 2.5451 - val_accuracy: 0.5195\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 81s 2s/step - loss: 0.1453 - accuracy: 0.9523 - val_loss: 2.5714 - val_accuracy: 0.5312\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 80s 2s/step - loss: 0.1649 - accuracy: 0.9338 - val_loss: 1.3487 - val_accuracy: 0.6758\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 74s 1s/step - loss: 0.1609 - accuracy: 0.9445 - val_loss: 3.6264 - val_accuracy: 0.5117\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 73s 1s/step - loss: 0.1512 - accuracy: 0.9503 - val_loss: 3.3309 - val_accuracy: 0.5273\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 74s 1s/step - loss: 0.1449 - accuracy: 0.9464 - val_loss: 2.8452 - val_accuracy: 0.5781\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 74s 1s/step - loss: 0.1113 - accuracy: 0.9620 - val_loss: 4.8912 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 80s 2s/step - loss: 0.1970 - accuracy: 0.9494 - val_loss: 3.1401 - val_accuracy: 0.5391\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 77s 1s/step - loss: 0.1054 - accuracy: 0.9737 - val_loss: 7.5553 - val_accuracy: 0.5000\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 75s 1s/step - loss: 0.0842 - accuracy: 0.9796 - val_loss: 2.8122 - val_accuracy: 0.6133\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 75s 1s/step - loss: 0.1763 - accuracy: 0.9659 - val_loss: 6.2925 - val_accuracy: 0.5039\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,epochs = 20 , validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
