{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Cats vs. Dogs Classification.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FH-ehiGm9OV",
        "colab_type": "text"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EmXtCq0ie_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "from shutil import copyfile\n",
        "import random\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L88bEAzrnv44",
        "colab_type": "text"
      },
      "source": [
        "**Downloading the Data into a Zip File and Extracting it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Dm_OeYcjXdv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "fe594120-967d-473f-ad1d-de0ee3f16aef"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
        "    -O \"/tmp/cats-and-dogs.zip\"\n",
        "\n",
        "local_zip = '/tmp/cats-and-dogs.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-04 06:51:11--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.38.114.234, 2600:1407:a800:1ac::e59, 2600:1407:a800:19e::e59\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.38.114.234|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
            "\n",
            "/tmp/cats-and-dogs. 100%[===================>] 786.68M  59.1MB/s    in 16s     \n",
            "\n",
            "2020-07-04 06:51:28 (47.8 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7T6oRUin9RC",
        "colab_type": "text"
      },
      "source": [
        "**Making Directories for Training and Testing Data**\n",
        "\n",
        "These directories have subdirectories as Cats and Dogs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w13fGgPCj8v1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    os.mkdir('/tmp/cats-v-dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n",
        "except OSError:\n",
        "    pass"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG8QC_F9ooh5",
        "colab_type": "text"
      },
      "source": [
        "**Data Preprocessing**\n",
        "\n",
        "In this we do the following things :\n",
        "\n",
        "\n",
        "1.   Extract Cat and Dog images from the directories\n",
        "2.   Split them into training and test data\n",
        "3.   Shuffle the data\n",
        "4.   Save them into destination directories created in the previous cell\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewvErSq_ifAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a9220a39-e615-4231-bed7-c328efeae19c"
      },
      "source": [
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    files = []\n",
        "    for filename in os.listdir(SOURCE):\n",
        "        file = SOURCE + filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[-testing_length:]\n",
        "\n",
        "    for filename in training_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TRAINING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in testing_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TESTING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "\n",
        "\n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
        "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
        "\n",
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "666.jpg is zero length, so ignoring.\n",
            "11702.jpg is zero length, so ignoring.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPwyN5nWpGe1",
        "colab_type": "text"
      },
      "source": [
        "**Checking if the above cell worked by listing the number of images in each directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo_0Oxo5kdZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e14bbe66-40b2-4340-ee15-2c092611d400"
      },
      "source": [
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11250\n",
            "11250\n",
            "1250\n",
            "1250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI4JnBtXpVRc",
        "colab_type": "text"
      },
      "source": [
        "**Initialising the ImageDataGenerator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBG5fEwYifAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = image.ImageDataGenerator(rescale=  1./255)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5AIMp9HifAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3beabae8-adc1-47a4-e3bd-40c80b8067a6"
      },
      "source": [
        "train_dir = '/tmp/cats-v-dogs/training/'\n",
        "test_dir = '/tmp/cats-v-dogs/testing/'\n",
        "train_data_gen = generator.flow_from_directory(train_dir, target_size=(150,150),class_mode='binary',batch_size=100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22498 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgSbrU6LpaeM",
        "colab_type": "text"
      },
      "source": [
        "**Building the Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JLA51CzifAJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "957ab31c-e67f-4035-f802-a9a1c556bf07"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16,(3,3),activation = 'relu', input_shape=(150,150,3)))\n",
        "model.add(MaxPool2D(2,2))\n",
        "\n",
        "model.add(Conv2D(32,(3,3),activation = 'relu', input_shape=(150,150,3)))\n",
        "model.add(MaxPool2D(2,2))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),activation = 'relu', input_shape=(150,150,3)))\n",
        "model.add(MaxPool2D(2,2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 148, 148, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 74, 74, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 72, 72, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 34, 34, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 18496)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               9470464   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 9,494,561\n",
            "Trainable params: 9,494,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcZDpnY9ifAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=RMSprop(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VLcatGNpfX4",
        "colab_type": "text"
      },
      "source": [
        "**Training the network and evaluating on the validation data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzW_rk2SifAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "8a69460b-1b82-404f-987f-3fcc46648409"
      },
      "source": [
        "model.fit(train_data_gen,epochs=5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "111/225 [=============>................] - ETA: 39s - loss: 0.4799 - accuracy: 0.7705"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "225/225 [==============================] - 80s 355ms/step - loss: 0.4695 - accuracy: 0.7781\n",
            "Epoch 2/5\n",
            "225/225 [==============================] - 80s 356ms/step - loss: 0.4014 - accuracy: 0.8169\n",
            "Epoch 3/5\n",
            "225/225 [==============================] - 80s 358ms/step - loss: 0.3372 - accuracy: 0.8535\n",
            "Epoch 4/5\n",
            "225/225 [==============================] - 79s 353ms/step - loss: 0.2686 - accuracy: 0.8851\n",
            "Epoch 5/5\n",
            "225/225 [==============================] - 80s 355ms/step - loss: 0.1992 - accuracy: 0.9202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9d72092f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-Mk0KTzifAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_generator = image.ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o7cCYs8ifAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "831ba65c-9df6-4f3e-d663-b5695d9aba56"
      },
      "source": [
        "test_data_gen = validation_generator.flow_from_directory(test_dir,target_size=(150,150),class_mode='binary',batch_size=20) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2500 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH94kGJ2qGSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f01c4282-2232-4069-ac82-f54fd3696786"
      },
      "source": [
        "model.evaluate(test_data_gen)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 9s 72ms/step - loss: 0.4338 - accuracy: 0.8368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.43376415967941284, 0.8367999792098999]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jftWmXuqMWw",
        "colab_type": "text"
      },
      "source": [
        "**We received an accuracy of 92% on training data and 83% on validation data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kh67FShqUwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}